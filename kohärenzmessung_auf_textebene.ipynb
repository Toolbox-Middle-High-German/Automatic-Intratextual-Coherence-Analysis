{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from Levenshtein import distance\n",
    "import pandas as pd\n",
    "import re\n",
    "from math import comb\n",
    "from tqdm import tqdm\n",
    "import heapq\n",
    "import multiprocessing\n",
    "from tqdm.contrib.concurrent import process_map"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Pfad zu Ordner, in der sich der durchzumessende Text befindet",
   "id": "f324528b4fc83c0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "filepath = \"/\"",
   "id": "f6b2d2924ad612b1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Modifizierbare Parameter",
   "id": "fab2f505e62628a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "laenge_ngrams = 2\n",
    "schwellenwert_orange = None\n",
    "schwellenwert_rot = None\n",
    "weights = {\n",
    "    ('ʒ', 'z'): 0,\n",
    "    ('z', 'ʒ'): 0,\n",
    "    ('uͦ', 'uo'): 0.5,\n",
    "    ('uo', 'uͦ'): 0.5,\n",
    "    ('vͦ', 'vu'): 0.5,\n",
    "    ('vu', 'vͦ'): 0.5,\n",
    "    ('wͦ', 'wo'): 0.5,\n",
    "    ('wo', 'wͦ'): 0.5,\n",
    "    ('Wͦ', 'Wo'): 0.5,\n",
    "    ('Wo', 'Wͦ'): 0.5,\n",
    "    ('Vͦ', 'Vo'): 0.5,\n",
    "    ('Vo', 'Vͦ'): 0.5,\n",
    "    ('ͤoͤ', 'oe'): 0.5,\n",
    "    ('oe', 'ͤoͤ'): 0.5,\n",
    "    ('vͤ', 've'): 0.5,\n",
    "    ('ve', 'vͤ'): 0.5,\n",
    "    ('iͤ', 'ie'): 0.5,\n",
    "    ('ie', 'iͤ'): 0.5,\n",
    "    ('uͤ', 'ue'): 0.5,\n",
    "    ('ue', 'uͤ'): 0.5,\n",
    "    ('ſ', 's'): 0,\n",
    "    ('s', 'ſ'): 0,\n",
    "    ('ſ', 'z'): 0,\n",
    "    ('z', 'ſ'): 0,\n",
    "    ('ä', 'ae'): 0,\n",
    "    ('ae', 'ä'): 0,\n",
    "    ('æ', 'ae'): 0,\n",
    "    ('ae', 'æ'): 0,\n",
    "    ('æ', 'ä'): 0,\n",
    "    ('ä', 'æ'): 0,\n",
    "    ('ö', 'oe'): 0.5,\n",
    "    ('oe', 'ö'): 0.5,\n",
    "    ('ü', 'ue'): 0.5,\n",
    "    ('ue', 'ü'): 0.5,\n",
    "    ('ß', 'ss'): 0.5,\n",
    "    ('ss', 'ß'): 0.5,\n",
    "    ('a', 'ä'): 0.75,\n",
    "    ('ä', 'a'): 0.75,\n",
    "    ('o', 'ö'): 0.75,\n",
    "    ('ö', 'o'): 0.75,\n",
    "    ('u', 'ü'): 0.75,\n",
    "    ('ü', 'u'): 0.75,\n",
    "    ('n̄', 'nn'): 0.5,\n",
    "    ('nn', 'n̄'): 0.5,\n",
    "    ('n̄', 'nt'): 0.5,\n",
    "    ('nt', 'n̄'): 0.5,\n",
    "    ('n̄', 'nd'): 0.5,\n",
    "    ('nd', 'n̄'): 0.5,\n",
    "    ('n̄', 'nde'): 0.5,\n",
    "    ('nde', 'n̄'): 0.5,\n",
    "    ('ē', 'en'): 0.5,\n",
    "    ('en', 'ē'): 0.5,\n",
    "    ('ē', 'em'): 0.5,\n",
    "    ('em', 'ē'): 0.5,\n",
    "    ('ā', 'an'): 0.5,\n",
    "    ('an', 'ā'): 0.5,\n",
    "    ('ā', 'am'): 0.5,\n",
    "    ('am', 'ā'): 0.5,\n",
    "    ('ū', 'un'): 0.5,\n",
    "    ('un', 'ū'): 0.5,\n",
    "    ('ū', 'um'): 0.5,\n",
    "    ('um', 'ū'): 0.5,\n",
    "    ('ẏ', 'i'): 0.5,\n",
    "    ('i', 'ẏ'): 0.5,\n",
    "    ('ẏ', 'j'): 0.5,\n",
    "    ('j', 'ẏ'): 0.5,\n",
    "    ('d͛', 'der'): 0,\n",
    "    ('der', 'd͛'): 0,\n",
    "    ('m͛', 'mer'): 0,\n",
    "    ('mer', 'm͛'): 0,\n",
    "    ('v͛', 'ver'): 0,\n",
    "    ('ver', 'v͛'): 0,\n",
    "    ('g͛', 'ger'): 0,\n",
    "    ('ger', 'g͛'): 0,\n",
    "    ('n͛', 'ner'): 0,\n",
    "    ('ner', 'n͛'): 0,\n",
    "    ('w͛', 'wer'): 0,\n",
    "    ('wer', 'w͛'): 0,\n",
    "    ('b͛', 'ber'): 0,\n",
    "    ('ber', 'b͛'): 0,\n",
    "    ('D͛', 'Der'): 0,\n",
    "    ('Der', 'D͛'): 0,\n",
    "    ('t͛', 'ter'): 0,\n",
    "    ('ter', 't͛'): 0,\n",
    "    ('oͮ', 'ov'): 0.5,\n",
    "    ('ov', 'oͮ'): 0.5,\n",
    "    ('oͮ', 'ou'): 0.5,\n",
    "    ('ou', 'oͮ'): 0.5,\n",
    "    ('vͥ', 'iv'): 0.5,\n",
    "    ('iv', 'vͥ'): 0.5,\n",
    "    ('vͥ', 'iu'): 0.5,\n",
    "    ('iu', 'vͥ'): 0.5,\n",
    "    ('ꝰ', 'us'): 0.5,\n",
    "    ('us', 'ꝰ'): 0.5,\n",
    "    ('v', 'u'): 0.5,\n",
    "    ('u', 'v'): 0.5,\n",
    "    ('v', 'f'): 0.5,\n",
    "    ('f', 'v'): 0.5,\n",
    "}"
   ],
   "id": "8eadf1cc48a2eac1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def main(path=filepath):\n",
    "    # Ao: Pfad zur Text-Datei (muss im txt-Format vorliegen)\n",
    "    dateiname = 'C:/Users/kiara/PycharmProjects/Kohärenz/hss/H-000.txt'\n",
    "    # Ao: Wie soll die Hs. in der finalen Tabelle genannt werden?\n",
    "    Name_fuer_Hs_in_Tabelle = 'H-000'\n",
    "    # Benennung der Zieldatei\n",
    "    benennung_ergebnisdatei = 'H-000_kohä_levg' + Name_fuer_Hs_in_Tabelle\n",
    "    zeilenumbrueche_hs = True\n",
    "    zeilenbeginn_abgesetzt = True\n",
    "    distance_type = 'lev_gew'\n",
    "\n",
    "    n = 1\n",
    "\n",
    "    display_LevD = True\n",
    "\n",
    "    grenzwerte_versch_distance_types = {'lev_n': [0.4, 0.7], 'lev_nn': [5, 10],\n",
    "                                        'lev_gew': [5, 10], 'jac': [0.4, 0.7],\n",
    "                                        'wmd': [0.25, 0.4]}\n",
    "\n",
    "    global schwellenwert_orange, schwellenwert_rot\n",
    "    if schwellenwert_orange is None:\n",
    "        schwellenwert_orange = grenzwerte_versch_distance_types[distance_type][0]\n",
    "    if schwellenwert_rot is None:\n",
    "        schwellenwert_rot = grenzwerte_versch_distance_types[distance_type][1]\n",
    "\n",
    "    # Fehlermeldung: 'UnpicklingError: pickle data was truncated'\n",
    "    # path_to_model = \"drive/MyDrive/corpora/mhdbdb-24-1.p\"\n",
    "    # with open(path_to_model, 'rb') as pickle_file:\n",
    "    #    model = pickle.load(pickle_file)\n",
    "\n",
    "    if zeilenumbrueche_hs is False:\n",
    "        if zeilenbeginn_abgesetzt is False:\n",
    "            # Einlesen der txt-Datei + Einfügen der Zeilenumbrüchen\n",
    "            hs = preparing_text_if_no_linebreaks(dateiname)\n",
    "        else:\n",
    "            hs = entferne_absetzung(preparing_text_if_no_linebreaks(dateiname))\n",
    "    else:\n",
    "        if zeilenbeginn_abgesetzt is False:\n",
    "            # Einlesen der txt-Datei\n",
    "            hs = preparing_text_verse_level(open_text_as_list_of_lines(dateiname))\n",
    "        else:\n",
    "            hs = entferne_absetzung(preparing_text_verse_level(\n",
    "                open_text_as_list_of_lines(dateiname)))\n",
    "\n",
    "    number_of_posbl_comb = comb(len(hs), 2)\n",
    "    #print(hs)\n",
    "    indices_hs = [x for x in range(0, len(hs))]\n",
    "\n",
    "    # csv-Datei\n",
    "    csv_file = open(\"levg_260624.csv\", 'w', encoding='utf-8', newline='')\n",
    "\n",
    "    # Benennung der Spalten\n",
    "    column_1 = 'Versnummer'\n",
    "    column_2 = 'Vers'\n",
    "    columns = [column_1, column_2]\n",
    "    n_columns_versnummer = [str(x) + '. Versnummer' for x in range(1, n + 1)]\n",
    "    n_columns_vers = [str(x) + '. Vers' for x in range(1, n + 1)]\n",
    "    n_columns_dis = [str(x) + f'. {distance_type}' for x in range(1, n + 1)]\n",
    "    for r in range(0, len(n_columns_vers)):\n",
    "        columns.append(n_columns_versnummer[r])\n",
    "        columns.append(n_columns_vers[r])\n",
    "        columns.append(n_columns_dis[r])\n",
    "    columns.append('Ende')  # Endmarkierung für die Funktion 'find_n_ms' -> wird in Ergebnisdatei entfernt\n",
    "\n",
    "\n",
    "    # parallelize\n",
    "    print(\"Number of cpu : \", multiprocessing.cpu_count())\n",
    "    #print(indices_hs)\n",
    "    verse_list = []\n",
    "    print(\"\\nMapping indices\")\n",
    "    for v_index in indices_hs:\n",
    "        verse_list.append(map_indices_to_verses(v_index, hs, columns, n, distance_type))\n",
    "\n",
    "    #p = multiprocessing.Pool(multiprocessing.cpu_count-4)\n",
    "\n",
    "\n",
    "    #results = p.map(calculate_distance_for_verse, verse_list)\n",
    "\n",
    "    # testing with first 60 indices\n",
    "    # do this to test your output structure, check for runtime errors or quickly estimate runtime for all indices\n",
    "    # verse_list = verse_list[:60]\n",
    "    results = process_map(calculate_distance_for_verse, verse_list, max_workers=multiprocessing.cpu_count())\n",
    "    sorted_results = sorted(results, key=lambda x: x[0])\n",
    "\n",
    "    print(\"\\nWriting results to \" + csv_file.name + \":\")\n",
    "    with csv_file:\n",
    "        header = columns\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=header)\n",
    "        writer.writeheader()\n",
    "        for result in tqdm(sorted_results):\n",
    "            v_index = result[0]\n",
    "            first_two_columns = {columns[0]: v_index, columns[1]: hs[v_index]}\n",
    "            final_columns = merge_two_dicts(first_two_columns, result[1])\n",
    "            writer.writerow(final_columns)\n",
    "\n",
    "def map_indices_to_verses(v_index, hs, columns, n, distance_type):\n",
    "    return [v_index, hs, columns, n, distance_type]\n",
    "\n",
    "\n",
    "def sort_verses(verses):\n",
    "    return sorted(verses, key=lambda x: x[0])\n",
    "\n",
    "def calculate_distance_for_verse(verse):\n",
    "    return [verse[0], compare_verses(verse[0], verse[1], verse[2], verse[3], verse[4])]\n",
    "\n",
    "\n",
    "# Berechnung Ähnlichkeit\n",
    "def calculate_distance(vers1, vers2, distance_type, we_model=None, weights=weights):\n",
    "    if distance_type == \"lev_n\":\n",
    "        return distance(vers1, vers2) / max(len(vers1), len(vers2))\n",
    "    elif distance_type == \"lev_nn\":\n",
    "        return distance(vers1, vers2)\n",
    "    elif distance_type == \"lev_gew\":\n",
    "        return weighted_levenshtein(vers1, vers2, weights)\n",
    "    elif distance_type == \"jac\":\n",
    "        list1, list2 = word2ngrams(vers1, laenge_ngrams), word2ngrams(vers2, laenge_ngrams)\n",
    "        intersection = len(list(set(list1).intersection(list2)))\n",
    "        anzahl_verschiedener_vorkommender_woerter = len(set(list1 + list2))\n",
    "        return 1 - (intersection / anzahl_verschiedener_vorkommender_woerter)\n",
    "\n",
    "\n",
    "#    elif distance_type == \"wmd\":\n",
    "#        return model.wv.wmdistance(vers1, vers2)\n",
    "\n",
    "# notwendig für Jaccard Distanz\n",
    "def word2ngrams(text, n):\n",
    "    return [\"\".join(j) for j in zip(*[text[i:] for i in range(n)])]\n",
    "\n",
    "\n",
    "# mithilfe von ChatGpt optimierte Funktion, ca. 10s/it\n",
    "def weighted_levenshtein(s1, s2, weights):\n",
    "    len1, len2 = len(s1), len(s2)\n",
    "\n",
    "    # Edge cases for empty strings\n",
    "    if len1 == 0:\n",
    "        return sum(weights.get(('', s2[j]), 1) for j in range(len2))\n",
    "    if len2 == 0:\n",
    "        return sum(weights.get((s1[i], ''), 1) for i in range(len1))\n",
    "\n",
    "    # Initialize the row for dynamic programming\n",
    "    current_row = [0] * (len2 + 1)\n",
    "\n",
    "    # Initialize the first row\n",
    "    for j in range(1, len2 + 1):\n",
    "        current_row[j] = current_row[j - 1] + weights.get(('', s2[j - 1]), 1)\n",
    "\n",
    "    for i in range(1, len1 + 1):\n",
    "        prev_val = current_row[0]\n",
    "        current_row[0] += weights.get((s1[i - 1], ''), 1)\n",
    "        for j in range(1, len2 + 1):\n",
    "            insert_cost = current_row[j - 1] + weights.get(('', s2[j - 1]), 1)\n",
    "            delete_cost = current_row[j] + weights.get((s1[i - 1], ''), 1)\n",
    "            if s1[i - 1] == s2[j - 1]:\n",
    "                substitute_cost = prev_val\n",
    "            else:\n",
    "                substitute_cost = prev_val + weights.get((s1[i - 1], s2[j - 1]), 1)\n",
    "\n",
    "            prev_val = current_row[j]\n",
    "            current_row[j] = min(insert_cost, delete_cost, substitute_cost)\n",
    "\n",
    "    return current_row[len2]\n",
    "\n",
    "\n",
    "# Preprocessing Sonderfall: Funktion zum Entfernen der Lücken\n",
    "# nach abgesetzten Buchstaben am Zeilenbeginn\n",
    "def entferne_absetzung(liste_verse: list):\n",
    "    result = []\n",
    "    for l in liste_verse:\n",
    "        l_chars = [a for a in l]\n",
    "        if l[1] == ' ':\n",
    "            del l_chars[1]\n",
    "            result.append(''.join(l_chars))\n",
    "        else:\n",
    "            result.append(l)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Einfügen von Versumbrüchen\n",
    "def preparing_text_if_no_linebreaks(filename_hs):\n",
    "    with open(filename_hs, mode='r', encoding='utf-8-sig') as f:\n",
    "        text_as_string_with_no_lb = f.read()\n",
    "        delimiter_replaced_by_lb = text_as_string_with_no_lb.translate({ord('.'): '\\n', ord('/'): '\\n', ord('·'): '\\n'})\n",
    "        whitespace_removed = ''.join(line.lstrip(' \\t') for line in delimiter_replaced_by_lb.splitlines(True))\n",
    "        prep_text = whitespace_removed.splitlines()\n",
    "        return prep_text\n",
    "\n",
    "\n",
    "# Texte in Liste einzelner Verse verwandeln\n",
    "def preparing_text_verse_level(text: list):\n",
    "    prep_text = list(filter(None, [t.replace('\\n', '') for t in text]))\n",
    "    return prep_text\n",
    "\n",
    "\n",
    "# Text als Liste einlesen (notwendig für Funktion 'preparing_text_verse_level')\n",
    "def open_text_as_list_of_lines(filename_hs):\n",
    "    with open(filename_hs, mode='r', encoding='utf-8-sig') as f:\n",
    "        liste_verse = f.readlines()\n",
    "        regex = re.compile(r'^### ?\\d{4}')\n",
    "        filtered = [i for i in liste_verse if not regex.match(i)]\n",
    "        return filtered\n",
    "\n",
    "\n",
    "def color_rule(val, lim_max_rot=schwellenwert_rot,\n",
    "               lim_max_orange=schwellenwert_orange):\n",
    "    result = []\n",
    "    for x in val:\n",
    "        if x == 'n.a.':\n",
    "            result.append('background-color: grey')\n",
    "        elif float(x) >= lim_max_rot:\n",
    "            result.append('background-color: red')\n",
    "        elif lim_max_rot > float(x) > lim_max_orange:\n",
    "            result.append('background-color: orange')\n",
    "        elif float(x) <= lim_max_orange:\n",
    "            result.append('background-color: green')\n",
    "        else:\n",
    "            result.append(None)\n",
    "    return result\n",
    "\n",
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()  # start with keys and values of x\n",
    "    z.update(y)  # modifies z with keys and values of y\n",
    "    return z\n",
    "\n",
    "\n",
    "def compare_verses(matching_vers_id: int, hs: list, columns: list, n: int,\n",
    "                   distance_type: str, display_LevD: bool = False):\n",
    "    heap = []\n",
    "    push = heapq.heappush\n",
    "    pop = heapq.heappushpop\n",
    "\n",
    "    for v_index in range(len(hs)):\n",
    "        if v_index != matching_vers_id:\n",
    "            calc_distance = calculate_distance(hs[v_index], hs[matching_vers_id], distance_type)\n",
    "            if len(heap) < n:\n",
    "                push(heap, (-calc_distance, v_index))\n",
    "            else:\n",
    "                pop(heap, (-calc_distance, v_index))\n",
    "\n",
    "    n_aehnlichste = {}\n",
    "    columns_copy = columns[2:]  # die ersten beiden columns ignorieren\n",
    "\n",
    "    for i, (neg_lev, v_id) in enumerate(sorted(heap, reverse=True)):\n",
    "        idx = i * 3\n",
    "        n_aehnlichste[columns_copy[idx]] = v_id\n",
    "        n_aehnlichste[columns_copy[idx + 1]] = hs[v_id]\n",
    "        n_aehnlichste[columns_copy[idx + 2]] = -neg_lev\n",
    "\n",
    "    return n_aehnlichste"
   ],
   "id": "3d9aea45109074b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "ef422b9fab011a81"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
